# Chain Matrix Multiplication

We want to reduce the total number of scalar product performed for the multiplication of a chain of given matrices <img src="/tex/9c831e51d275d4379a6fb434db7baec6.svg?invert_in_darkmode&sanitize=true" align=middle width=103.69663754999999pt height=22.465723500000017pt/> through applying optimal parenthesizations.

The ideal way to perform this is to recursively compute optimal parenthesizations and use dynamic programming to avoid the number of possible parenthesization to explode.

We recursively compute the product of all matrices between <img src="/tex/4ebf880807deff5796460f39aea46f80.svg?invert_in_darkmode&sanitize=true" align=middle width=16.97969789999999pt height=22.465723500000017pt/> and <img src="/tex/58c9277a170088a03229936790d23a98.svg?invert_in_darkmode&sanitize=true" align=middle width=18.433308299999993pt height=22.465723500000017pt/> by assuming that the optimal split is <img src="/tex/f0ceda683b001e134cdb1aefd556d5a6.svg?invert_in_darkmode&sanitize=true" align=middle width=169.4196768pt height=24.65753399999998pt/> with k ranging from <img src="/tex/77a3b857d53fb44e33b53e4c8b68351a.svg?invert_in_darkmode&sanitize=true" align=middle width=5.663225699999989pt height=21.68300969999999pt/> to <img src="/tex/fda4e6a332eec2a3985445b0c195f6f6.svg?invert_in_darkmode&sanitize=true" align=middle width=36.02081834999999pt height=21.68300969999999pt/> and summing the recursively computed product between <img src="/tex/4ebf880807deff5796460f39aea46f80.svg?invert_in_darkmode&sanitize=true" align=middle width=16.97969789999999pt height=22.465723500000017pt/> and <img src="/tex/1f0aa5770083d7bade7ac8aafcbfc008.svg?invert_in_darkmode&sanitize=true" align=middle width=19.594827449999993pt height=22.465723500000017pt/>, between <img src="/tex/62cf929e2634af1a76d9f286191f4752.svg?invert_in_darkmode&sanitize=true" align=middle width=36.23874869999999pt height=22.465723500000017pt/> and <img src="/tex/58c9277a170088a03229936790d23a98.svg?invert_in_darkmode&sanitize=true" align=middle width=18.433308299999993pt height=22.465723500000017pt/> and the total number of scalar products needed to compute the product between the two recursive subproblems (represented by the dimensions of the resulting matrices <img src="/tex/31bfa54cf15dcbc5b0e7226b57420929.svg?invert_in_darkmode&sanitize=true" align=middle width=29.74803479999999pt height=14.15524440000002pt/>, <img src="/tex/a28020cb9b58a3a875adec3adf5d824a.svg?invert_in_darkmode&sanitize=true" align=middle width=15.536596349999991pt height=14.15524440000002pt/> and <img src="/tex/7f131a60c8e7bb2b22f383f7bd49e2c0.svg?invert_in_darkmode&sanitize=true" align=middle width=14.37507554999999pt height=14.15524440000002pt/>). The product of those matrices is then minimized w.r.t. <img src="/tex/63bb9849783d01d91403bc9a5fea12a2.svg?invert_in_darkmode&sanitize=true" align=middle width=9.075367949999992pt height=22.831056599999986pt/>. The stopping condition is that the product is 0 when <img src="/tex/987386704e03b06431fd3b428745d2e7.svg?invert_in_darkmode&sanitize=true" align=middle width=35.29127414999999pt height=21.68300969999999pt/>, which represent the case in which we are simply trying to compute the product between two matrices, in which the number of scalar product is given simply by the scalar products between the two matrices (no recursive subproblems).

We use a matrix <img src="/tex/0e51a2dede42189d77627c4d742822c3.svg?invert_in_darkmode&sanitize=true" align=middle width=14.433101099999991pt height=14.15524440000002pt/> to store the number of multiplication computed that way and a matrix <img src="/tex/6f9bad7347b91ceebebd3ad7e6f6f2d1.svg?invert_in_darkmode&sanitize=true" align=middle width=7.7054801999999905pt height=14.15524440000002pt/> to store the k that minimizes the number of multiplication for the current subproblem (e.g. k = 3 means that we obtain the best parenthesization by placing a parenthesis after the third element of the chain).

Inside <img src="/tex/0e51a2dede42189d77627c4d742822c3.svg?invert_in_darkmode&sanitize=true" align=middle width=14.433101099999991pt height=14.15524440000002pt/>, in position <img src="/tex/aa20264597f5a63b51587e0581c48f2c.svg?invert_in_darkmode&sanitize=true" align=middle width=33.46496009999999pt height=24.65753399999998pt/> i will find the minimal number of scalar multiplications needed to solve the chain matrix multiplication between matrices <img src="/tex/4ebf880807deff5796460f39aea46f80.svg?invert_in_darkmode&sanitize=true" align=middle width=16.97969789999999pt height=22.465723500000017pt/> and <img src="/tex/58c9277a170088a03229936790d23a98.svg?invert_in_darkmode&sanitize=true" align=middle width=18.433308299999993pt height=22.465723500000017pt/> of the original chain <img src="/tex/ffc837aba8842ae16d8ecf072e5ab32f.svg?invert_in_darkmode&sanitize=true" align=middle width=151.18680224999997pt height=22.465723500000017pt/>.

By performing the same task iteratively we can avoid recursion and thus avoid the memory required by each step.

The complexity of the algorithm is <img src="/tex/3286dca1e85ee4b6f9b9bc1457937d59.svg?invert_in_darkmode&sanitize=true" align=middle width=42.81220349999999pt height=26.76175259999998pt/>, where n is the size of the chain. This result is much better than the original complexity to perform matrix multiplication, which is <img src="/tex/87eb576da43f75827ce99382390153e0.svg?invert_in_darkmode&sanitize=true" align=middle width=42.73801454999999pt height=24.65753399999998pt/>.